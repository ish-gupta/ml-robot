{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishit\\AppData\\Local\\Temp\\ipykernel_2660\\3261988653.py:56: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_augmented = pd.concat([df_augmented, df_augmented_entry], ignore_index=True)\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:/Users/ishit/Documents/ROSbot_data_collection/datasets/training_data_3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ishit\\Documents\\ROSbot_data_collection\\training\\augment_attempt2.ipynb Cell 1\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/augment_attempt2.ipynb#W0sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39m# Save the augmented DataFrame to CSV\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/augment_attempt2.ipynb#W0sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m df_augmented\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_folder, \u001b[39m'\u001b[39m\u001b[39mdata_augmented.csv\u001b[39m\u001b[39m'\u001b[39m), index\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/augment_attempt2.ipynb#W0sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m df_original\u001b[39m.\u001b[39;49mto_csv(image_folder_path, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[0;32m   3903\u001b[0m     path_or_buf,\n\u001b[0;32m   3904\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[0;32m   3905\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[0;32m   3906\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m   3907\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m   3908\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m   3909\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[0;32m   3910\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   3911\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[0;32m   3912\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m   3913\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[0;32m   3914\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[0;32m   3915\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[0;32m   3916\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[0;32m   3917\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[0;32m   3918\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m   3919\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[0;32m   1154\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[0;32m    248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[0;32m    249\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    250\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    251\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[0;32m    252\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[0;32m    253\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[0;32m    254\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:/Users/ishit/Documents/ROSbot_data_collection/datasets/training_data_3'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def augment_brightness(image, factor=0.7):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv[:, :, 2] = np.clip(hsv[:, :, 2] * factor, 0, 255)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "def augment_flip(image):\n",
    "    return cv2.flip(image, 1)  # 1 for horizontal flip\n",
    "\n",
    "def augment_blur(image, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(image, kernel_size, 0)\n",
    "\n",
    "def apply_augmentation(image_path, linear_speed_x, angular_speed_z, is_turning, output_folder, df_augmented):\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if (angular_speed_z >= 0.8 or angular_speed_z <= -0.8) and is_turning == \"True\":\n",
    "\n",
    "        for i in range(5):\n",
    "            augmented_image1 = augment_brightness(image)\n",
    "            save_path1 = os.path.join(output_folder, os.path.basename(image_path).replace('.jpg', f'_brightness_{i}.jpg'))\n",
    "            cv2.imwrite(save_path1, augmented_image1)\n",
    "\n",
    "            augmented_image2 = augment_blur(image)\n",
    "            save_path2 = os.path.join(output_folder, os.path.basename(image_path).replace('.jpg', f'_blur_{i}.jpg'))\n",
    "            cv2.imwrite(save_path2, augmented_image2)\n",
    "            \n",
    "            # Update CSV for augmented images\n",
    "            df_augmented_entry = pd.DataFrame({'image name': [os.path.basename(save_path1), os.path.basename(save_path2)],\n",
    "                                               'linear_speed_x': [linear_speed_x, linear_speed_x],\n",
    "                                               'angular_speed_z': [angular_speed_z, -angular_speed_z]})\n",
    "            \n",
    "            # Append the augmented entry to the existing DataFrame\n",
    "            df_augmented = pd.concat([df_augmented, df_augmented_entry], ignore_index=True)\n",
    "\n",
    "    if angular_speed_z >= 0.8 or angular_speed_z <= -0.8:\n",
    "\n",
    "        for i in range(2):\n",
    "            augmented_image1 = augment_brightness(image)\n",
    "            save_path1 = os.path.join(output_folder, os.path.basename(image_path).replace('.jpg', f'_brightness_{i}.jpg'))\n",
    "            cv2.imwrite(save_path1, augmented_image1)\n",
    "\n",
    "            augmented_image2 = augment_blur(image)\n",
    "            save_path2 = os.path.join(output_folder, os.path.basename(image_path).replace('.jpg', f'_blur_{i}.jpg'))\n",
    "            cv2.imwrite(save_path2, augmented_image2)\n",
    "            \n",
    "            # Update CSV for augmented images\n",
    "            df_augmented_entry = pd.DataFrame({'image name': [os.path.basename(save_path1), os.path.basename(save_path2)],\n",
    "                                               'linear_speed_x': [linear_speed_x, linear_speed_x],\n",
    "                                               'angular_speed_z': [angular_speed_z, -angular_speed_z]})\n",
    "            \n",
    "            # Append the augmented entry to the existing DataFrame\n",
    "            df_augmented = pd.concat([df_augmented, df_augmented_entry], ignore_index=True)\n",
    "    \n",
    "    elif angular_speed_z <= 0.3 and angular_speed_z >= -0.3:\n",
    "        # Find the index of the entry in the original DataFrame\n",
    "        index_to_update = df_original.index[df_original['image name'] == image_file].tolist()[0]\n",
    "\n",
    "        # Update the entry in the original DataFrame with negated values\n",
    "        df_original.loc[index_to_update, 'angular_speed_z'] = -angular_speed_z\n",
    "\n",
    "    return df_augmented, df_original\n",
    "\n",
    "# Read the original CSV file\n",
    "csv_file_path = r\"C:/Users/ishit/Documents/ROSbot_data_collection/datasets/training_data_3/data1.csv\"\n",
    "df_original = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Specify the output folder for augmented images\n",
    "output_folder = r\"C:/Users/ishit/Documents/ROSbot_data_collection/datasets/augment_YES/\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Initialize an empty DataFrame for augmented data\n",
    "columns = ['image name', 'linear_speed_x', 'angular_speed_z', 'is_turning']\n",
    "df_augmented = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Iterate through images in the folder\n",
    "image_folder_path = r\"C:/Users/ishit/Documents/ROSbot_data_collection/datasets/training_data_3\"\n",
    "original_samples = len(df_original)\n",
    "\n",
    "for image_file in os.listdir(image_folder_path):\n",
    "    if image_file.endswith('.jpg'):\n",
    "        image_path = os.path.join(image_folder_path, image_file)\n",
    "        linear_speed_x = df_original.loc[df_original['image name'] == image_file, 'linear_speed_x'].values[0]\n",
    "        angular_speed_z = df_original.loc[df_original['image name'] == image_file, 'angular_speed_z'].values[0] \n",
    "        is_turning = df_original.loc[df_original['image name'] == image_file, 'is_turning'].values[0] \n",
    "        df_augmented, df_original = apply_augmentation(image_path, linear_speed_x, angular_speed_z, is_turning, output_folder, df_augmented)\n",
    "\n",
    "# Save the augmented DataFrame to CSV\n",
    "df_augmented.to_csv(os.path.join(output_folder, 'data_augmented.csv'), index=False)\n",
    "df_original.to_csv(image_folder_path, index=False, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
