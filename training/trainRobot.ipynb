{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishit\\Documents\\ROSbot_data_collection\\training\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\python311.zip\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\DLLs\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\n",
      "\n",
      "C:\\Users\\ishit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\n",
      "C:\\Users\\ishit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\win32\n",
      "C:\\Users\\ishit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\win32\\lib\n",
      "C:\\Users\\ishit\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\Pythonwin\n",
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1776.0_x64__qbz5n2kfra8p0\\Lib\\site-packages\n",
      "C:\\Users\\ishit\\Documents\\ROSbot_data_collection\\models\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# import h5py\n",
    "import os\n",
    "# from PIL import Image\n",
    "# import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "# import csv\n",
    "from DatasetGenerator import MultiDirectoryDataSequence\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\ishit\\Documents\\ROSbot_data_collection\\models')\n",
    "for path in sys.path:\n",
    "    print(path)\n",
    "from DAVE2pytorch import DAVE2PytorchModel, DAVE2v1, DAVE2v2, DAVE2v3, Epoch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import Compose, ToPILImage, ToTensor, Resize, Lambda, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishit\\AppData\\Local\\Temp\\ipykernel_85520\\939559012.py:34: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.\n",
      "  model = DAVE2v3(input_shape=input_shape)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "parse_arguments() missing 1 required positional argument: 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ishit\\Documents\\ROSbot_data_collection\\training\\trainRobot.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m         f\u001b[39m.\u001b[39mwrite(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m=}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtotal_samples=\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39mget_total_samples()\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00margs\u001b[39m.\u001b[39mepochs\u001b[39m=}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtime_to_train\u001b[39m=}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdirs=\u001b[39m\u001b[39m{\u001b[39;00mdataset\u001b[39m.\u001b[39mget_directories()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m     main()\n",
      "\u001b[1;32mc:\\Users\\ishit\\Documents\\ROSbot_data_collection\\training\\trainRobot.ipynb Cell 2\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m input_shape \u001b[39m=\u001b[39m (\u001b[39m135\u001b[39m, \u001b[39m240\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m model \u001b[39m=\u001b[39m DAVE2v3(input_shape\u001b[39m=\u001b[39minput_shape)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m args \u001b[39m=\u001b[39m parse_arguments()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mprint\u001b[39m(args)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m dataset \u001b[39m=\u001b[39m MultiDirectoryDataSequence(args\u001b[39m.\u001b[39mdataset, image_size\u001b[39m=\u001b[39m(model\u001b[39m.\u001b[39minput_shape[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), transform\u001b[39m=\u001b[39mCompose([ToTensor()]),\\\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/ishit/Documents/ROSbot_data_collection/training/trainRobot.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                                      robustification\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mrobustification, noise_level\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mnoisevar) \u001b[39m#, Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: parse_arguments() missing 1 required positional argument: 'args'"
     ]
    }
   ],
   "source": [
    "def parse_arguments(args):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('dataset', type=str, help='parent directory of training dataset')\n",
    "    parser.add_argument(\"--batch\", type=int, default=64)\n",
    "    parser.add_argument(\"--epochs\", type=int, default=100)\n",
    "    parser.add_argument(\"--lr\", type=float, default=1e-4)\n",
    "    parser.add_argument(\"--robustification\", type=bool, default=True)\n",
    "    parser.add_argument(\"--noisevar\", type=int, default=15)\n",
    "    parser.add_argument(\"--log_interval\", type=int, default=50)\n",
    "    return parser.parse_args(args)\n",
    "\n",
    "\n",
    "def characterize_steering_distribution(y_steering, generator):\n",
    "    turning = []; straight = []\n",
    "    for i in y_steering:\n",
    "        if abs(i) < 0.1:\n",
    "            straight.append(abs(i))\n",
    "        else:\n",
    "            turning.append(abs(i))\n",
    "    # turning = [i for i in y_steering if i > 0.1]\n",
    "    # straight = [i for i in y_steering if i <= 0.1]\n",
    "    try:\n",
    "        print(\"Moments of abs. val'd turning steering distribution:\", generator.get_distribution_moments(turning))\n",
    "        print(\"Moments of abs. val'd straight steering distribution:\", generator.get_distribution_moments(straight))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"len(turning)\", len(turning))\n",
    "        print(\"len(straight)\", len(straight))\n",
    "\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    input_shape = (135, 240)\n",
    "    model = DAVE2v3(input_shape=input_shape)\n",
    "    args = parse_arguments()\n",
    "    print(args)\n",
    "    dataset = MultiDirectoryDataSequence(args.dataset, image_size=(model.input_shape[::-1]), transform=Compose([ToTensor()]),\\\n",
    "                                         robustification=args.robustification, noise_level=args.noisevar) #, Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])]))\n",
    "\n",
    "    print(\"Retrieving output distribution....\")\n",
    "    print(\"Moments of distribution:\", dataset.get_outputs_distribution())\n",
    "    print(\"Total samples:\", dataset.get_total_samples())\n",
    "    def worker_init_fn(worker_id):\n",
    "        np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "    trainloader = DataLoader(dataset, batch_size=args.batch, shuffle=True, worker_init_fn=worker_init_fn)\n",
    "    print(\"time to load dataset: {}\".format(time.time() - start_time))\n",
    "\n",
    "    iteration = f'{model._get_name()}-{input_shape[0]}x{input_shape[1]}-lr{args.lr}-{args.epochs}epoch-{args.batch}batch-lossMSE-{int(dataset.get_total_samples()/1000)}Ksamples-INDUSTRIALandHIROCHIandUTAH-noiseflipblur'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"{iteration=}\")\n",
    "    print(f\"{device=}\")\n",
    "    model = model.to(device)\n",
    "    # if loss doesnt level out after 20 epochs, either inc epochs or inc learning rate\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr) #, betas=(0.9, 0.999), eps=1e-08)\n",
    "    lowest_loss = 1e5\n",
    "    logfreq = 20\n",
    "    for epoch in range(args.epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, hashmap in enumerate(trainloader, 0):\n",
    "            x = hashmap['image'].float().to(device)\n",
    "            y = hashmap['steering_input'].float().to(device)\n",
    "            x = Variable(x, requires_grad=True)\n",
    "            y = Variable(y, requires_grad=False)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(x)\n",
    "            # loss = F.mse_loss(outputs.flatten(), y)\n",
    "            loss = F.mse_loss(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if i % logfreq == logfreq-1:  # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.7f' %\n",
    "                      (epoch + 1, i + 1, running_loss / logfreq))\n",
    "                if (running_loss / logfreq) < lowest_loss:\n",
    "                    print(f\"New best model! MSE loss: {running_loss / logfreq}\")\n",
    "                    model_name = f\"./model-fixnoise-{iteration}-best.pt\"\n",
    "                    print(f\"Saving model to {model_name}\")\n",
    "                    torch.save(model, model_name)\n",
    "                    lowest_loss = running_loss / logfreq\n",
    "                running_loss = 0.0\n",
    "        print(f\"Finished {epoch=}\")\n",
    "        model_name = f\"H:/GitHub/DAVE2-Keras/model-fixnoise-{iteration}-epoch{epoch}.pt\"\n",
    "        print(f\"Saving model to {model_name}\")\n",
    "        torch.save(model, model_name)\n",
    "        # if loss < 0.002:\n",
    "        #     print(f\"Loss at {loss}; quitting training...\")\n",
    "        #     break\n",
    "    print('Finished Training')\n",
    "\n",
    "    # save model\n",
    "    # torch.save(model.state_dict(), f'H:/GitHub/DAVE2-Keras/test{iteration}-weights.pt')\n",
    "    model_name = f'H:/GitHub/DAVE2-Keras/model-{iteration}.pt'\n",
    "    torch.save(model, model_name)\n",
    "\n",
    "    # delete models from previous epochs\n",
    "    print(\"Deleting models from previous epochs...\")\n",
    "    for epoch in range(args.epochs):\n",
    "        os.remove(f\"H:/GitHub/DAVE2-Keras/model-{iteration}-epoch{epoch}.pt\")\n",
    "    print(f\"Saving model to {model_name}\")\n",
    "    print(\"All done :)\")\n",
    "    time_to_train=time.time() - start_time\n",
    "    print(\"Time to train: {}\".format(time_to_train))\n",
    "    # save metainformation about training\n",
    "    with open(f'H:/GitHub/DAVE2-Keras/model-{iteration}-metainfo.txt', \"w\") as f:\n",
    "        f.write(f\"{model_name=}\\n\"\n",
    "                f\"total_samples={dataset.get_total_samples()}\\n\"\n",
    "                f\"{args.epochs=}\\n\"\n",
    "                f\"{args.lr=}\\n\"\n",
    "                f\"{args.batch=}\\n\"\n",
    "                f\"{optimizer=}\\n\"\n",
    "                f\"final_loss={running_loss / logfreq}\\n\"\n",
    "                f\"{device=}\\n\"\n",
    "                f\"{args.robustification=}\\n\"\n",
    "                f\"{args.noisevar=}\\n\"\n",
    "                f\"dataset_moments={dataset.get_outputs_distribution()}\\n\"\n",
    "                f\"{time_to_train=}\\n\"\n",
    "                f\"dirs={dataset.get_directories()}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
